{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9e69810",
   "metadata": {},
   "source": [
    "# SynFlow Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a2af85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6115d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    dataset = 'mnist' #mnist, tiny-imagenet, cifar10, cifar100\n",
    "    model = 'conv' # fc, vgg11, resnet20 or resnet18 (tiny)\n",
    "#     model_class = 'lottery' #lottery (vgg11, resnet20), tinyimagenet (vgg11, resnet18)\n",
    "    dense_classifier = False\n",
    "    pretrained = False\n",
    "    optimizer = 'adam'\n",
    "    train_batch_size = 64\n",
    "    test_batch_size = 256\n",
    "    train_epochs = 2\n",
    "    # what about stopping the IMP when the sparsity is reached?\n",
    "    lr = 0.001\n",
    "    lr_drops = tuple([])\n",
    "    lr_drop_rate = 0.1\n",
    "    weight_decay = 0.0\n",
    "    pruner= 'NP'\n",
    "    compression= 10.0\n",
    "    iter_comp = .2 # % retained values per iteration\n",
    "    compression_schedule= 'exponential'\n",
    "    mask_scope= 'global'\n",
    "    prune_dataset_ratio= 10\n",
    "    prune_batch_size= 256\n",
    "    prune_bias= False\n",
    "    prune_batchnorm= False\n",
    "    prune_residual= False\n",
    "    prune_train_mode= False\n",
    "    reinitialize= False\n",
    "    shuffle= False\n",
    "    invert= False\n",
    "    experiment = 'BK'\n",
    "    expid = True\n",
    "    result_dir = 'Results/data'\n",
    "    gpu = 0\n",
    "    workers =4\n",
    "    seed = 1\n",
    "    no_cuda= True#'store_true'\n",
    "    verbose= True#'store_true'\n",
    "    trial = 0\n",
    "    save = True\n",
    "    verbose = True\n",
    "    # Extra arguments for rewinding, Renda et al 2020(1)\n",
    "    rewind = 'weight' # Choose your own rewinding adventure! ('LR', 'weight', 'NP')\n",
    "    ## Only pertinent for traditional rewinding as seen in Renda et al.\n",
    "    rewind_epochs = 2 # how far back to rewind? (Only for weight rewinding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c0cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()\n",
    "if args.dataset == 'mnist':\n",
    "    setattr(args, 'model_class', 'default')\n",
    "elif args.dataset == 'cifar10' or args.dataset == 'cifar100':\n",
    "    setattr(args, 'model_class', 'lottery')\n",
    "elif args.dataset == 'tiny-imagenet':\n",
    "    setattr(args, 'model_class', 'tinyimagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ea5cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## In case of argument mistakes\n",
    "# if args.rewind == None:\n",
    "#     args.rewind = 'None'\n",
    "#     args.prune_epochs = None\n",
    "#     args.rewind_epochs = None\n",
    "# elif args.rewind == 'NP':\n",
    "#     args.rewind_train = None\n",
    "#     args.rewind_epochs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d972785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct Result Directory ##\n",
    "if args.expid == False:\n",
    "    print(\"WARNING: this experiment is not being saved.\")\n",
    "    setattr(args, 'save', False)\n",
    "else:\n",
    "    expid = args.rewind+'_'+args.pruner+'_'+args.dataset+'_'+args.model+'_trial_'+str(args.trial)\n",
    "    result_dir = '{}/{}/{}'.format(args.result_dir, args.experiment, expid)\n",
    "    setattr(args, 'save', True)\n",
    "    setattr(args, 'result_dir', result_dir)\n",
    "    os.makedirs(result_dir, exist_ok = True)\n",
    "            \n",
    "print('Expt ID: ' + expid) \n",
    "print('Pruner: ' + args.pruner)\n",
    "print('Rewind Method: ' + args.rewind)\n",
    "# print('Train epochs before rewind: ' + str(args.prune_epochs))\n",
    "# print('Epochs to rewind: ' + str(args.rewind_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d42bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Args ##\n",
    "if args.save:\n",
    "    with open(args.result_dir + '/args.json', 'w') as f:\n",
    "        json.dump(args.__dict__, f, sort_keys=True, indent=4)\n",
    "\n",
    "## Run Experiment ##\n",
    "import numpy as np\n",
    "best_acc = -np.Inf\n",
    "\n",
    "\"\"\"\n",
    "Custom experiment for the work done by Balwani & Krzyston 2021\n",
    "Based off of singleshot.py & multishot.py seen in the Ganguli Lab SynFlow repo\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from Utils import load\n",
    "from Utils import generator\n",
    "from Utils import metrics_Jay\n",
    "from train import *\n",
    "from prune import *\n",
    "from Experiments import singleshot\n",
    "\n",
    "#     if args.rewind == None:\n",
    "#         singleshot.run(args)\n",
    "\n",
    "#     else:\n",
    "\n",
    "## Random Seed and Device ##\n",
    "torch.manual_seed(args.seed)\n",
    "device = load.device(args.gpu)\n",
    "\n",
    "## Data ##\n",
    "print('Loading {} dataset.'.format(args.dataset))\n",
    "input_shape, num_classes = load.dimension(args.dataset) \n",
    "prune_loader = load.dataloader(args.dataset, args.prune_batch_size, True, args.workers, args.prune_dataset_ratio * num_classes)\n",
    "train_loader = load.dataloader(args.dataset, args.train_batch_size, True, args.workers)\n",
    "test_loader = load.dataloader(args.dataset, args.test_batch_size, False, args.workers)\n",
    "\n",
    "## Model ##\n",
    "print('Creating {} model.'.format(args.model))\n",
    "model = load.model(args.model, args.model_class)(input_shape, \n",
    "                                                 num_classes, \n",
    "                                                 args.dense_classifier,\n",
    "                                                 args.pretrained).to(device)\n",
    "\n",
    "## Compute NP ratios ##\n",
    "args.compression_list, layers_n_shapes, total_comp = metrics_Jay.eta_c_compute(args.model, model, args.dataset, input_shape, args.gpu, verbose = True)\n",
    "# loss = nn.CrossEntropyLoss()\n",
    "# opt_class, opt_kwargs = load.optimizer(args.optimizer)\n",
    "# optimizer = opt_class(generator.parameters(model), lr=args.lr, weight_decay=args.weight_decay, **opt_kwargs)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=args.lr_drops, gamma=args.lr_drop_rate)\n",
    "\n",
    "# ## Save Initialiized Weights ##\n",
    "# torch.save(model.state_dict(),\"{}/model_init.pt\".format(args.result_dir))\n",
    "# torch.save(optimizer.state_dict(),\"{}/optimizer.pt\".format(args.result_dir))\n",
    "# torch.save(scheduler.state_dict(),\"{}/scheduler.pt\".format(args.result_dir))\n",
    "\n",
    "\n",
    "# # Train to completion\n",
    "# print('Training for {} epochs'.format(str(args.train_epochs)))\n",
    "# for epoch in range(args.train_epochs):            \n",
    "#     # Train\n",
    "#     model.train()\n",
    "#     total = 0\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data)\n",
    "#         train_loss = loss(output, target)\n",
    "#         total += train_loss.item() * data.size(0)\n",
    "#         train_loss.backward()\n",
    "#         optimizer.step()\n",
    "#     print('Train Epoch: {} \\tLoss: {:.6f}'.format(\n",
    "#         epoch, train_loss.item()))\n",
    "\n",
    "#     # Eval\n",
    "#     model.eval()\n",
    "#     total = 0\n",
    "#     correct1 = 0\n",
    "#     correct5 = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data, target in test_loader:\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             output = model(data)\n",
    "#             total += loss(output, target).item() * data.size(0)\n",
    "#             _, pred = output.topk(5, dim=1)\n",
    "#             correct = pred.eq(target.view(-1, 1).expand_as(pred))\n",
    "#             correct1 += correct[:,:1].sum().item()\n",
    "#             correct5 += correct[:,:5].sum().item()\n",
    "#     average_loss = total / len(test_loader.dataset)\n",
    "#     accuracy1 = 100. * correct1 / len(test_loader.dataset)\n",
    "#     accuracy5 = 100. * correct5 / len(test_loader.dataset)\n",
    "#     print('Evaluation: Average loss: {:.4f}, Top 1 Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "#             average_loss, correct1, len(test_loader.dataset), accuracy1))\n",
    "\n",
    "#     # Save weights if best performance\n",
    "#     if accuracy1 > best_acc:\n",
    "#         torch.save(model.state_dict(),\"{}/model_best.pt\".format(args.result_dir))\n",
    "#         best_acc = accuracy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c651250-ef4c-42a9-8b34-7fe9608e2b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef32edbc-7fc7-4af6-b26c-3efbbdc5ed57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a971602-c6c1-4f79-bc7d-b07d80be8df6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4e96f0-3e70-4b93-90bb-cb44dad3e974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b225b98d-b807-4b96-9e2e-1120e5122e57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afe38d3-dc10-42f0-a28e-68fc0ae01b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcc8723-8ee4-4df0-9b10-476e706d22c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4decc9cb-6c21-4927-a4a2-8ccf2201c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO:\n",
    "- get it from aish\n",
    "- get it tunning our own way\n",
    "- run experiments\n",
    "\"\"\"\n",
    "\n",
    "if args.pruner == 'NP':\n",
    "#     pruner = \n",
    "    continue\n",
    "elif:\n",
    "    pruner = load.pruner(args.pruner)(generator.masked_parameters(model, args.prune_bias, args.prune_batchnorm, args.prune_residual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41f459a-8188-4501-aadb-a3a6409c2737",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = 1\n",
    "comp -= args.iter_comp*comp\n",
    "print('Sparsity = {}'.format(str(round(1-comp,4))))\n",
    "pruner.score(model, loss, test_loader, device, in_out_sizes)\n",
    "pruner.mask(1 - comp, args.mask_scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05d9f56-29a1-4289-81f4-cba313ecedcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mask, param in pruner.masked_parameters:\n",
    "#     score = pruner.scores[id(param)]\n",
    "#     k = int((1.0 - sparsity) * score.numel())\n",
    "#     if not k < 1:\n",
    "#         threshold, _ = torch.kthvalue(torch.flatten(score), k)\n",
    "#         zero = torch.tensor([0.]).to(mask.device)\n",
    "#         one = torch.tensor([1.]).to(mask.device)\n",
    "#         mask.copy_(torch.where(score <= threshold, zero, one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05c074b-7d3f-4d86-9676-a8a641d8aaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c50082e-942d-47c4-ae28-da28a5e6b3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_out_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068fc3dc-286a-49f4-acb4-8e17de7e4afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    if p.requires_grad:\n",
    "        print(p.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6fcf20-2e9f-4f13-96df-4c0d348d8a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd48314c-34e8-40ae-ae30-b124ce69acf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea367be0-5d42-4582-83d3-3526deda897b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb78d101-81b2-48ad-8702-d192d01266c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605dca78-180b-4ea3-904b-cf4181bf5ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa964b6-c6ed-4b49-87d8-d1fe3ed8e743",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if name == 'conv.weight':\n",
    "        print(name)\n",
    "        torch.save(param, './test_conv.pt')\n",
    "    if name == 'fc.weight':\n",
    "        print(name)\n",
    "        torch.save(param, './test_dense.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5317eb-4b62-40b2-a845-ed601cb25e95",
   "metadata": {},
   "source": [
    "#### TODO #####\n",
    "- prune by layer\n",
    "- load compression ratios\n",
    "- this method, this ratio @ this layers\n",
    "- module.kernel_size\n",
    "- compute net compression ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0abc9ec-ba45-4202-a04a-6ff685486c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eta_c, in_out_shapes = eta_c_compute(args.model, args.dataset, input_shape, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037585d3-8c43-48d5-b83b-ab1444eb2dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in model.named_modules():\n",
    "    if 'conv' in name:\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce8f64a-314e-40a6-b858-c424c9a94038",
   "metadata": {},
   "outputs": [],
   "source": [
    "module.kernel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55be12a4-3da2-4a66-ab6f-1fc38557f7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = tuple([1,input_shape[0],input_shape[1],input_shape[2]])\n",
    "out = torch.rand((shape)) \n",
    "outs = []\n",
    "eta_c = []\n",
    "ind = 0\n",
    "for name, module in model.named_modules():\n",
    "    import torch.nn.functional as F\n",
    "    mod = module.eval()\n",
    "    outs.append(out.shape)\n",
    "    if ind+1 < len(names):\n",
    "        if 'conv' in name:\n",
    "            out = mod(torch.tensor(out).float().to(device))\n",
    "            if outs[-1][2] != out.shape[2]: # account for downsampling\n",
    "                outs[-1] = torch.rand((1,int(outs[-1][1]*2),int(outs[-1][2]/2),int(outs[-1][3]/2))).shape\n",
    "            m = (outs[-1][2]+2)*(outs[-1][3]+2) #dimensions of input\n",
    "            n = out.shape[2]*out.shape[3] #dimensions of output\n",
    "            eta_c.append((n*(3**2))/(m+n-1)) # kernel size is 3\n",
    "            ind += 1\n",
    "        if 'fc' in name: # otherwise it's the dense layer\n",
    "            out = F.avg_pool2d(out, out.size()[3])\n",
    "            out = out.view(out.size(0), -1)\n",
    "            out = mod(torch.tensor(out).float().to(device))\n",
    "            eta_c.append((module.in_features*module.out_features)/(module.in_features+module.out_features-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1332b947-4571-40c5-8305-949080c2f91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0b85bf-740e-4613-b147-34d4de8ad7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d44abb-0537-4494-8690-64a72e97a43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand((1,int(outs[-1][1]*2),int(outs[-1][2]/2),int(outs[-1][3]/2))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21649d6-40c2-4062-b428-32c77ebce9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.rand((shape))  \n",
    "for name, module in model.named_modules():\n",
    "        if 'classifier' in name:\n",
    "            if name[-1].isnumeric():\n",
    "                if name[-1] == '0':\n",
    "                    out = out.view(out.size(0), -1)\n",
    "                if '0' in name or '3' in name or '6' in name:\n",
    "                    print(name)\n",
    "                    mod = module.eval()\n",
    "                    print(\"Dense In: \" + str(out.shape[-1]))\n",
    "                    out = mod(out.float().to(device))\n",
    "                    print(\"Dense Out: \" + str(out.shape[-1])) \n",
    "        elif 'features' in name:\n",
    "            if name[-1].isnumeric():\n",
    "                print(name)\n",
    "                mod = module.eval()\n",
    "                out = mod(out.float().to(device))\n",
    "                print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30e911c-6b8b-46ff-9f72-b0e26c8f5c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d1fc9d-5ae3-4bca-bf41-028e8bdc5802",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.rand((shape))  \n",
    "avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "for name, module in model.named_modules():\n",
    "    if name != '' and 'residual' not in name:\n",
    "        if '0' in name and '_x' not in name and '.' in name: \n",
    "            # cover the very first conv layer\n",
    "            print(name)\n",
    "            mod = module.eval()\n",
    "            out = mod(out.float().to(device))\n",
    "            print(out.shape)\n",
    "        elif '_x' in name and 'residual' not in name and 'shortcut' not in name and name[-1].isnumeric():\n",
    "            # every other conv layer that is not in residual nor shortut\n",
    "            print(name)\n",
    "            mod = module.eval()\n",
    "            out = mod(out.float().to(device))\n",
    "            print(out.shape)\n",
    "        elif name == 'fc':\n",
    "            # dense layers, will need to change with different sized resnets \n",
    "            # (number of dense layers will change)\n",
    "            print(name)\n",
    "            out = avg_pool(out)\n",
    "            out = out.view(out.size(0), -1)\n",
    "            mod = module.eval()\n",
    "            print(\"Dense In: \" + str(out.shape[-1]))\n",
    "            out = mod(out.float().to(device))\n",
    "            print(\"Dense Out: \" + str(out.shape[-1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3669298c-5cb9-4a61-92b0-bc15b2fb5da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffabbc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fb2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()[list(model.state_dict().keys())[i]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a397a1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from Utils import load\n",
    "# from Utils import generator\n",
    "# from Utils import metrics_Jay\n",
    "# from train import *\n",
    "# from prune import *\n",
    "\n",
    "# ## Random Seed and Device ##\n",
    "# torch.manual_seed(args.seed)\n",
    "# device = load.device(args.gpu)\n",
    "\n",
    "# ## Data ##\n",
    "# print('Loading {} dataset.'.format(args.dataset))\n",
    "# input_shape, num_classes = load.dimension(args.dataset) \n",
    "# prune_loader = load.dataloader(args.dataset, args.prune_batch_size, True, args.workers, args.prune_dataset_ratio * num_classes)\n",
    "# train_loader = load.dataloader(args.dataset, args.train_batch_size, True, args.workers)\n",
    "# test_loader = load.dataloader(args.dataset, args.test_batch_size, False, args.workers)\n",
    "\n",
    "# ## Model ##\n",
    "# print('Creating {} model.'.format(args.model))\n",
    "# model = load.model(args.model, args.model_class)(input_shape, \n",
    "#                                                  num_classes, \n",
    "#                                                  args.dense_classifier,\n",
    "#                                                  args.pretrained).to(device)\n",
    "\n",
    "# loss = nn.CrossEntropyLoss()\n",
    "# opt_class, opt_kwargs = load.optimizer(args.optimizer)\n",
    "# optimizer = opt_class(generator.parameters(model), lr=args.lr, weight_decay=args.weight_decay, **opt_kwargs)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=args.lr_drops, gamma=args.lr_drop_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b780a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewind a fully trained network\n",
    "\n",
    "# load model\n",
    "model.load_state_dict(torch.load(\"{}/model_best.pt\".format(args.result_dir), map_location=device))\n",
    "\n",
    "# load pruner\n",
    "pruner = load.pruner(args.pruner)(generator.masked_parameters(model, args.prune_bias, args.prune_batchnorm, args.prune_residual))\n",
    "\n",
    "print('Target Compression Ratio: {}\\n'.format(str(args.compression)))\n",
    "\n",
    "# Initialize conditions for pruning loop\n",
    "comp = 1\n",
    "\n",
    "# Reset Optimizer, and Scheduler\n",
    "optimizer.load_state_dict(torch.load(\"{}/optimizer.pt\".format(args.result_dir), map_location=device))\n",
    "scheduler.load_state_dict(torch.load(\"{}/scheduler.pt\".format(args.result_dir), map_location=device))\n",
    "\n",
    "# Prune Model\n",
    "comp -= args.iter_comp*comp\n",
    "print('Sparsity = {}'.format(str(round(1-comp,4))))\n",
    "pruner.score(model, loss, test_loader, device)\n",
    "pruner.mask(1 - comp, args.mask_scope)\n",
    "\n",
    "# Find the actual compression ratio\n",
    "remaining_params, total_params = pruner.stats()\n",
    "comp = total_params/(total_params-remaining_params)\n",
    "print('New Compression: {}'.format(str(round(comp,4))))\n",
    "\n",
    "print('Training for {} epochs'.format(str(args.prune_epochs)))\n",
    "epoch = 0\n",
    "for l in range(args.prune_epochs):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        train_loss = loss(output, target)\n",
    "        total += train_loss.item() * data.size(0)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "    # Save weights\n",
    "    torch.save(model.state_dict(),\"{}/prune_epoch_{}.pt\".format(args.result_dir, str(epoch)))\n",
    "    epoch += 1\n",
    "    \n",
    "# Eval\n",
    "print('Evaluating Pruned model')\n",
    "model.eval()\n",
    "total = 0\n",
    "correct1 = 0\n",
    "correct5 = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        total += loss(output, target).item() * data.size(0)\n",
    "        _, pred = output.topk(5, dim=1)\n",
    "        correct = pred.eq(target.view(-1, 1).expand_as(pred))\n",
    "        correct1 += correct[:,:1].sum().item()\n",
    "        correct5 += correct[:,:5].sum().item()\n",
    "average_loss = total / len(test_loader.dataset)\n",
    "accuracy1 = 100. * correct1 / len(test_loader.dataset)\n",
    "accuracy5 = 100. * correct5 / len(test_loader.dataset)\n",
    "print('Evaluation: Average loss: {:.4f}, Top 1 Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        average_loss, correct1, len(test_loader.dataset), accuracy1))\n",
    "\n",
    "\n",
    "# Prune Result\n",
    "prune_result = metrics_Jay.summary(model, \n",
    "                               pruner.scores,\n",
    "                               metrics_Jay.flop(model, input_shape, device),\n",
    "                               lambda p: generator.prunable(p, args.prune_batchnorm, args.prune_residual))\n",
    "\n",
    "# Save Data\n",
    "prune_result.to_pickle(\"{}/compression-{}-{}.pkl\".format(args.result_dir, args.pruner, str(round(comp, 4))))\n",
    "\n",
    "while comp <= args.compression:\n",
    "    # Reset Optimizer, and Scheduler\n",
    "    optimizer.load_state_dict(torch.load(\"{}/optimizer.pt\".format(args.result_dir), map_location=device))\n",
    "    scheduler.load_state_dict(torch.load(\"{}/scheduler.pt\".format(args.result_dir), map_location=device))\n",
    "        \n",
    "    # Prune Model\n",
    "    comp = comp**(-1) - (args.iter_comp*(comp**(-1)))\n",
    "    print('Sparsity = {}'.format(str(round(1-comp,4))))\n",
    "    pruner.mask(1 - comp, args.mask_scope)\n",
    "#     remaining_params, total_params = pruner.stats()\n",
    "#     comp = total_params/(total_params-remaining_params)\n",
    "#     print('New Compression: {}'.format(str(round(comp,4))))\n",
    "    \n",
    "    # Weight rewind\n",
    "    if args.rewind =='weight': # or args.weight == 'NP':\n",
    "        weights_epoch = args.prune_epochs - args.rewind_epochs\n",
    "        model.load_state_dict(torch.load(\"{}/prune_epoch_{}.pt\".format(args.result_dir, str(weights_epoch), map_location=device)))\n",
    "        print('Weights rewound')\n",
    "        # Apply the mask \n",
    "        pruner.mask(1 - comp, args.mask_scope)\n",
    "    \n",
    "    remaining_params, total_params = pruner.stats()\n",
    "    comp = total_params/(total_params-remaining_params)\n",
    "    print('New Compression: {}'.format(str(round(comp,4))))\n",
    "    \n",
    "    print('Training for {} epochs'.format(str(args.prune_epochs)))\n",
    "    for l in range(args.prune_epochs):\n",
    "        # Train for specified number of epochs\n",
    "        model.train()\n",
    "        total = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            train_loss = loss(output, target)\n",
    "            total += train_loss.item() * data.size(0)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        # Save weights\n",
    "        torch.save(model.state_dict(),\"{}/prune_epoch_{}.pt\".format(args.result_dir, str(epoch)))\n",
    "        epoch += 1        \n",
    "    \n",
    "    # Eval\n",
    "    print('Evaluating Pruned model')\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct1 = 0\n",
    "    correct5 = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            total += loss(output, target).item() * data.size(0)\n",
    "            _, pred = output.topk(5, dim=1)\n",
    "            correct = pred.eq(target.view(-1, 1).expand_as(pred))\n",
    "            correct1 += correct[:,:1].sum().item()\n",
    "            correct5 += correct[:,:5].sum().item()\n",
    "    average_loss = total / len(test_loader.dataset)\n",
    "    accuracy1 = 100. * correct1 / len(test_loader.dataset)\n",
    "    accuracy5 = 100. * correct5 / len(test_loader.dataset)\n",
    "    print('Evaluation: Average loss: {:.4f}, Top 1 Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "            average_loss, correct1, len(test_loader.dataset), accuracy1))\n",
    "\n",
    "    # Save weights\n",
    "    torch.save(model.state_dict(),\"{}/pruned_{}.pt\".format(args.result_dir, str(round(comp, 4))))\n",
    "\n",
    "    # Prune Result\n",
    "    prune_result = metrics_Jay.summary(model, \n",
    "                                   pruner.scores,\n",
    "                                   metrics_Jay.flop(model, input_shape, device),\n",
    "                                   lambda p: generator.prunable(p, args.prune_batchnorm, args.prune_residual))\n",
    "\n",
    "    # Save Data\n",
    "    prune_result.to_pickle(\"{}/compression-{}-{}.pkl\".format(args.result_dir, args.pruner, str(round(comp, 4))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba6ae95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f2a447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f973864c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2552942b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f646721b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
